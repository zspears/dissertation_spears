#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
Introduction
\end_layout

\begin_layout Subsection*
Motivation
\end_layout

\begin_layout Standard
Optimization has been the one of the main goals of computational since the
 beginning of computing.
 Designing something to perform optimally in all conditions is the end goal,
 but for the most part we simply focus on local optimization for a single
 application at a time.
 Optimization takes time, however.
 The optimization process can be a very long and arduous task of changing
 the value of a single variable each time and running a new simulation to
 determine what should be done with the new variable value.
 This leads to many simulations for a small benefit.
 This type of optimization tends to be so costly that it prohibits very
 large scale optimizations simply because of run time.
\end_layout

\begin_layout Standard
With this problem in mind, adjoint based optimization was implemented.
 Adjoint based optimization allows for optimization of a multitude of control
 variables in a single simulation.
 The process simply runs the simulation forward to the end of the interaction
 and then maps back the simulation values for each step with a reverse solver
 to determine the direction and magnitude that the control variables should
 be moved.
 Adjoint based optimization is not without flaws itself.
 To run an iteration of adjoint based optimization, the code must run the
 entire forward simulation, while storing every step for use in the reverse
 solver.
 This proves to be very costly for simulations of large size in either the
 time or space components.
 For real world problems, we often need at least one of those components
 to be very large, usually both.
 To get valid results for use with actual problems, we need high fidelity
 in the results, which means we need at least fairly fine meshes in the
 simulation region leading to even larger amounts of data to be stored for
 the reverse solver.
 
\end_layout

\begin_layout Standard
The adjoint problem becomes intractible for the naive approach of just simply
 writing out every step and then reading it back in when necessary.
 For this reason, the concept of checkpointing was originally applied.
 Checkpointing allows for the execution of adjoint-based optimization with
 a greatly reduced need for storage space.
 With checkpoionting, one runs a forward simulation and instead of storing
 every step, only stores a few checkpoints from which to restart the forward
 solver when the reverse solver gets to the point where it needs the steps
 between them.
 This greatly reduces the need for storage space to run a simulation.
 With improvements in how the checkpointing is done, the possible simulations
 are becoming larger and longer.
 Thanks to these advances, adjont based optimization has now become applicable
 to very large problems.
 We introduce a new implementation of checkpointing that allows for adjoint-base
d optiomization of fully 3D jet flows and noise caused by them.
\end_layout

\begin_layout Standard
Jet engine noise is a problem as old as jet fighters themselves.
 As the engines got and continue to get more powerful, the problem of engine
 noise gets continually worse.
 When looking at aircraft carriers, the problem is even larger.
 The solution to jet engine noise in commercial airliners has been universally
 to increase the bypass ratio.
 Increasing the bypass ratio allows for more cold air to be blown around
 the jet engine in the cowlings around the outside.
 This makes for a much larger mixing layer along with making for a much
 slower transition from the ambient air to the hot and fast jet engine exhaust.
 This is not feasible for military jets as the high demands on military
 jets mean that the loss of possible thrust to pushing the bypass air around
 the engine is completely unacceptable.
 Not only are there many jets on the carrier and taking off nearly constantly,
 but the workers on the deck of the carrier are exposed to the jet noise
 from a distance much less than anywhere else.
 This creates a situation that can be extremely dangerous for the hearing
 of the aircraft carrier deck workers.
 Under OSHA regulations, a person working on the deck of a modern aircraft
 carrier could work less than eight minutes before needing to take a full
 day off.
 The noise is even more pervasive, given that when the workers retire from
 the deck for the day, they sleep only a few floors below the source of
 the noise, thus getting exposed to a portion of the noise even in down
 time.
\end_layout

\begin_layout Standard
For the simulation of the real noise generated by the jets, one also has
 to take into account the material properties of the jet engine as well
 as the cowlings and exhaust materials.
 If the materials are too flexible, the jet exhaust tip may deform and lose
 thrust or possibly cause the flow to be even more over or underexpanded,
 leading to even more noise.
 This need leads to the need of a Fluid-Structure interaction feature in
 the code.
 
\end_layout

\begin_layout Subsection*
Background
\end_layout

\begin_layout Subsubsection*
CFD
\end_layout

\begin_layout Standard
Computational Fluid Dynamics is a field of computational physics that models
 the flows of fluids.
 This uses boundary conditions and definitions of the gas or fluid constitution
 in order to simulate the interaction of the fluids in the flow and the
 surrounding fluid.
 Computational Fluid Dynamics is able to simulate a range of interactions
 and can be used for both compressible and incompressible fluids.
 Turbulent jet modeling is a major application of CFD that is used in this
 paper.
 One can also use CFD to model the propogation of propeller wakes in submarines
 leading to a very similar signature to whale trails.
 This method has been used recently to help in finding submarines travelling
 at reasonable depths that were otherwise invisible to the naked eye or
 radar.
 The uses of CFd are countless and these are just a few that have some tactical
 relationship to the research at hand.
 
\end_layout

\begin_layout Subsubsection*
Compressible Fluids
\end_layout

\begin_layout Standard
Compressible Fluids are those that can be pushed into a smaller space at
 the cost of raising the pressure in the containment.
 For example, air is a compressible fluid.
 One can take easily a 50 mL container of air and compress it into a 30
 mL container.
 The only difference would be the work to force the air in and the difference
 in the pressure and such of the air after it was compressed into the smaller
 space.
 
\end_layout

\begin_layout Subsubsection*
Incompressible Fluids
\end_layout

\begin_layout Standard
Incompressible Fluids cannot be forced into a container of smaller volume.
 For example, water is an incompressible fluid.
 If one tries to take 50 mL of water and press it into a 30 mL container,
 it simply cannot be done.
 This is because water is incompressible.
 
\end_layout

\begin_layout Subsubsection*
LES
\end_layout

\begin_layout Standard
Large Eddy Simulations are simulations of fluid dynamics that include near
 field and far field flows of trubulent flows.
 They allow for better resolution than RANS models and better computational
 efficiency than DNS models.
 
\end_layout

\begin_layout Subsubsection*
Unsteady Simulations
\end_layout

\begin_layout Standard
The simulations used in the studies are unsteady in nature, meaning that
 the flow does not ever reach a steady state and is in constant flux.
 
\end_layout

\begin_layout Subsubsection*
Unstructured Grids
\end_layout

\begin_layout Standard
The code is built on unstructured grids, allowing for much more intricate
 geometries than are possible for the same number of elements in a structured
 code.
 It also allows for easier refinement in some regions without need for global
 refinement.
 
\end_layout

\begin_layout Subsubsection*
CSD
\end_layout

\begin_layout Standard
Computational Structural Dynamics models the motion and reaction of solids
 during collisions and in response to stresses from inside and outside forces.
 THis allows for simulations of large scale structures as well as possibly
 the modeling of the very small scale structure of the material itself.
 In CSD one may model and entire building and how it would respond to a
 collision with a vehicle of some sort, or oen could model the interaction
 of molecules betweeen a shoe and the sidewalk in simulating a person walking.
 CSD has been used in the determination of strength of materials for a long
 time.
 This tells the breaking point of the material due to stress and is very
 important in the design of buildings and building materials as well as
 the field related to this paper of body armor materials.
 Current body armor material models, however, do leave a bit to be desired
 in the matchign of theoretical to actual limits of stopping power.
 
\end_layout

\begin_layout Subsubsection*
FSI
\end_layout

\begin_layout Standard
Fluid-Structure Interaction is a coupling of a fluid solver with a structural
 sover in order to model the reaction of a solid to changes in a fluid flow
 and in return the reactions of the fluid flow to the solid and the changes
 in the solid.
 Fluid structure interaction is used for thisngs such as blast mitigation
 for buildings and blast damage analysis.
 It is also used to test ships' sea worthiness without having to actually
 put a ship out to sea and risk the lives of the people who would have to
 be manning the vessel.
\end_layout

\begin_layout Subsubsection*
Adjoint-Based Optimization
\end_layout

\begin_layout Standard
Optimization of a flow with respect to a certain trait that one would like
 to minimize or maximize.
 Given a control surface with n points, adjoint-based optimization can give
 a large step toward the optimal solution for roughly the cost of 2-3 forward
 simulation compared to n forward simulations with standard optimization
 techniques.
 Storage and communication requirements tend to be a limiting factor for
 adjoint-based optimization making it prohibitively costly without additional
 estimation or other advances.
 
\end_layout

\begin_layout Standard
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\end_layout

\begin_layout Standard
Fix this and get it in the right form for what we are currently using.
 This is the old notation but at least is a notation.
\end_layout

\begin_layout Standard
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\end_layout

\begin_layout Standard
This problem is set as a set of parameters, 
\begin_inset Formula $\beta$
\end_inset

, effecting a flow field, 
\begin_inset Formula $U(\beta)$
\end_inset

.
 Inside the simulation there will be the flow domain, 
\begin_inset Formula $\Omega$
\end_inset

, along with the boundary, 
\begin_inset Formula $\Gamma$
\end_inset

.
 We will use the 
\begin_inset Formula $\Gamma$
\end_inset

 to describe the boundaries of the entire domain as just 
\begin_inset Formula $\Gamma$
\end_inset

 while the boundary of the target area is described by 
\begin_inset Formula $\Gamma_{trg}$
\end_inset

 and the boundary of the design region, or what we will be changing to minimize
 the effect of the blast on the target, will be shown by 
\begin_inset Formula $\Gamma_{dsg}$
\end_inset

.
 We assume that we cannot change the target surface with changes to the
 design surface, therefore the boundaries of the target and design surfaces
 will never overlap.
 
\begin_inset Formula 
\[
\Gamma_{trg}\bigcap\Gamma_{dsg}=\emptyset
\]

\end_inset

 We talk about a cost function, J, that is affected by the parameters and
 the flow field.
 Knowing though that the design and target regions cannot overlap, then
 the cost function can only be changed by the flow field itself, since all
 changes will have to move through the flow field, 
\begin_inset Formula $U(\beta)$
\end_inset

, to get from design, 
\begin_inset Formula $\Gamma_{dsg}$
\end_inset

, to target, 
\begin_inset Formula $\Gamma_{trg}$
\end_inset

.
 then we can write the cost funtion only as a function of the flow field
 namely, 
\begin_inset Formula $J(U(\beta))$
\end_inset

.
 this cost function can be broken up into two parts just as the entire region
 was.
 these parts are the flow domain and the boundary.
 Hence, 
\begin_inset Formula 
\begin{equation}
J=J_{\Omega}+J_{\Gamma}=\int_{0}^{T}\int_{\Omega_{trg}}j_{\Omega}d\Omega dt+\int_{0}^{T}\int_{\Gamma_{trg}}j_{\Gamma}d\Gamma dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For the physics we use the unsteady Euler equations given by 
\begin_inset Formula 
\begin{equation}
R=\frac{\partial U}{\partial t}+\frac{\partial F_{i}}{\partial x_{i}}=\frac{\partial U}{\partial t}+\frac{\partial U}{\partial x_{i}}\cdot\frac{\partial F_{i}}{\partial U}=\frac{\partial U}{\partial t}+\underline{\underbar{A}}_{i}\cdot\frac{\partial U}{\partial x_{i}}=0.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula 
\[
U=\begin{pmatrix}\rho\\
\rho v_{i}\\
\rho e
\end{pmatrix}\;\; and\;\; F_{j}=\begin{pmatrix}\rho v_{j}\\
\rho v_{j}v_{i}+p\delta_{ij}\\
v_{j}(\rho e+p)
\end{pmatrix}.
\]

\end_inset

 
\end_layout

\begin_layout Standard
We only declare the cost function on the boundary, so then 
\begin_inset Formula $J_{\Omega}=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $U$
\end_inset

 is the vector of conserved quantities
\end_layout

\begin_layout Standard
\begin_inset Formula $F_{i}$
\end_inset

 is the flux vector in the direction of i
\end_layout

\begin_layout Standard
\begin_inset Formula $\rho$
\end_inset

 is the density of the fluid
\end_layout

\begin_layout Standard
\begin_inset Formula $v=\begin{pmatrix}v_{x}\\
v_{y}\\
v_{z}
\end{pmatrix}$
\end_inset

 for three dimensional problems or 
\begin_inset Formula $v=\begin{pmatrix}v_{x}\\
v_{y}
\end{pmatrix}$
\end_inset

 for two dimensional problems
\end_layout

\begin_layout Standard
Then 
\begin_inset Formula $v_{i}$
\end_inset

 is the velocity in one of the directions
\end_layout

\begin_layout Standard
\begin_inset Formula $e$
\end_inset

 is the total energy
\end_layout

\begin_layout Standard
\begin_inset Formula $\underline{\underbar{A}}_{i}$
\end_inset

 is the jacobian matrix again in a given direction
\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset

 is the pressure and is related to the 
\begin_inset Formula $U$
\end_inset

 variables by the polytropic gas relation 
\begin_inset Formula $p=(\gamma-1)\rho(e-\frac{v_{k}^{2}}{2})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $\gamma$
\end_inset

 is the ratio of specific heats, taken to be 1.4 as the standard value
\end_layout

\begin_layout Standard
\begin_inset Formula $J_{\Gamma_{1}}$
\end_inset

 is the impulse on the target area
\end_layout

\begin_layout Standard
\begin_inset Formula $J_{\Gamma_{2}}$
\end_inset

 is the mean pressure peak on the target area
\end_layout

\begin_layout Standard
\begin_inset Formula $J_{\Gamma_{3}}$
\end_inset

 is the quadratic posititve deviation from a set threshold pressure
\end_layout

\begin_layout Standard
\begin_inset Formula $J_{\Gamma_{4}}$
\end_inset

 is a mixture of 
\begin_inset Formula $J_{\Gamma_{1}}$
\end_inset

 and 
\begin_inset Formula $J_{\Gamma_{2}}$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula $A_{trg}$
\end_inset

 is the area of the target window
\end_layout

\begin_layout Standard
\begin_inset Formula $\Delta T_{th}$
\end_inset

 is the amount of time the pressure threshold is exceeded in the target
 window
\end_layout

\begin_layout Standard
\begin_inset Formula $p_{0}$
\end_inset

 is the ambient pressure
\end_layout

\begin_layout Standard
\begin_inset Formula $p_{th}$
\end_inset

 is the threshold pressure
\end_layout

\begin_layout Standard
\begin_inset Formula $T$
\end_inset

 is the total time of the simulation
\end_layout

\begin_layout Standard
Impulse on a target area is defined as: 
\begin_inset Formula 
\begin{align}
J_{\Gamma_{1}}=I & =\int_{0}^{T}\int_{\Gamma_{1}}j\Gamma_{1}d\Gamma dt\nonumber \\
 & =\int_{0}^{T}\int_{\Gamma_{trg}}max(p-p0,0)d\Gamma dt
\end{align}

\end_inset


\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Standard
Mean pressure peaks 
\begin_inset Formula $\bar{p}$
\end_inset

 acting upon the target area is defined as:
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $ $
\end_inset


\begin_inset Formula $ $
\end_inset


\begin_inset Formula 
\begin{align}
J_{\Gamma_{2}}=\bar{p} & =\int_{0}^{T}\int_{\Gamma_{trg}}j\Gamma_{2}d\Gamma dt\nonumber \\
 & =\frac{1}{A_{trg}\Delta T_{th}}\int_{0}^{T}\int_{\Gamma_{trg}}\frac{max(p-p_{th},0)}{p-p_{th}+\epsilon}(p-p_{0})d\Gamma dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The quadratic positive deviation from threshold pressure on the target area
 is defined as: 
\begin_inset Formula 
\begin{align}
J_{\Gamma_{3}} & =\int_{0}^{T}\int_{\Gamma_{trg}}j\Gamma_{3}d\Gamma dt\nonumber \\
 & =\int_{0}^{T}\int_{\Gamma_{trg}}\frac{1}{2}[max(p-p_{th},0)]^{2}d\Gamma dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The change in impulse is defined as: 
\begin_inset Formula $ $
\end_inset


\begin_inset Formula 
\begin{align}
\delta J_{\Gamma}^{(l)}=\delta I^{(l)} & =\int_{0}^{T}\int_{\Gamma_{trg}}\delta p^{(l)}\frac{\partial j\Gamma_{1}}{\partial p}d\Gamma dt\nonumber \\
 & =\int_{0}^{T}\int_{\Gamma_{trg}}\delta p^{(l)}\frac{max(p-p_{0},0)}{p-p_{0}+\epsilon}d\Gamma dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The change in pressure peaks 
\begin_inset Formula $\bar{p}$
\end_inset

 is defined as: 
\begin_inset Formula 
\begin{align}
\delta J_{\Gamma_{2}}^{(l)}=\delta\bar{p}^{(l)} & =\int_{0}^{T}\int_{\Gamma_{trg}}\delta p^{(l)}\frac{\partial j\Gamma_{2}}{\partial p}d\Gamma dt\nonumber \\
 & =\frac{1}{A_{trg}\Delta T_{th}}\int_{0}^{T}\int_{\Gamma_{trg}}\delta p^{(l)}\frac{max(p-p_{th},0)}{p-p_{th}+\epsilon}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
A case specific weighting of change in impulse and mean pressure peaks respectiv
ely is defined as: 
\begin_inset Formula 
\begin{align}
\delta J_{\Gamma_{4}}^{(l)} & =\alpha\delta J_{\Gamma_{1}}^{*(l)}+(1-\alpha)\delta J_{\Gamma_{2}}^{*(l)}\nonumber \\
 & =\alpha\frac{\delta J_{\Gamma_{1}}^{(l)}}{A_{trg}Tp_{0}}+(1-\alpha)\frac{\delta J_{\Gamma_{2}}^{(l)}}{p_{0}}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula $\alpha$
\end_inset

 defined as: 
\begin_inset Formula 
\begin{align*}
\alpha & =\left(\frac{\frac{p}{p_{0}}}{\frac{I}{p_{0}TA_{trg}}}+1\right)^{-1}\\
 & =\left(\frac{pTA_{trg}}{I}+1\right)^{-1}\\
 & =\frac{I}{pTA_{trg}+I}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
with simplification, we reach: 
\begin_inset Formula 
\begin{equation}
\delta J_{\Gamma_{4}}^{*(l)}=\int_{0}^{T}\int_{\Gamma_{trg}}\delta p^{(l)}\frac{\partial j\Gamma_{4}}{\partial p}d\Gamma dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula 
\begin{align*}
\frac{\partial j\Gamma_{4}}{\partial p} & =\frac{1}{A_{trg}p_{0}}[\frac{\alpha}{T}\frac{max(p-p_{0},0)}{p-p_{0}+\epsilon}\\
 & +\frac{1-\alpha}{\Delta T_{th}}\frac{max(p-p_{th},0)}{p-p_{th}+\epsilon}
\end{align*}

\end_inset


\end_layout

\begin_layout LyX-Code
\begin_inset Formula 
\begin{align}
-\frac{\partial\hat{U}}{\partial t}-\frac{\partial F_{i}}{\partial U}\cdot\frac{\partial\hat{U}}{\partial x_{i}}=-\frac{\partial\hat{U}}{\partial t}-\underline{\underbar{A}}_{i}^{T}\cdot\frac{\partial\hat{U}}{\partial x_{i}} & =0\;\text{ in }\Omega\backslash\Omega_{trg}\nonumber \\
-\frac{\partial\hat{U}}{\partial t}-\underline{\underbar{A}}_{i}^{T}\cdot\frac{\partial\hat{U}}{\partial x_{i}} & =-\frac{\partial j_{\Omega}}{\partial U}\;\text{ in }\Omega_{trg}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\delta U^{(l)}\cdot\frac{F_{n}}{\partial U}\cdot\hat{U} & =0\;\text{ on }\Gamma\backslash\Gamma_{trg}\nonumber \\
\delta U^{(l)}\cdot\left[\frac{\partial F_{n}}{\partial U}\cdot\hat{U}+\frac{\partial j_{\Gamma}}{\partial U}\right] & =0\thickspace\text{ on }\Gamma_{trg}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\delta\beta$
\end_inset

 is shape variation
\end_layout

\begin_layout Standard
\begin_inset Formula $\delta x(\delta\beta)$
\end_inset

 is displacement in interior and boundary nodes
\end_layout

\begin_layout Standard
linear variation of flow variables:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\delta U^{(lc)}=\delta U^{(l)}+\delta U^{(c)}=\delta U^{(l)}+\delta x\cdot\nabla U
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\delta U^{(l)}$
\end_inset

 is local variation
\end_layout

\begin_layout Standard
\begin_inset Formula $\delta U^{(c)}$
\end_inset

 is convective variation
\end_layout

\begin_layout Standard
Total variation of cost function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\delta J^{(t)}=\delta J^{(lc)}+\delta J^{(g)}=\delta J^{(l)}+\delta J^{(c)}+\delta J^{(g)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\delta J^{(g)}$
\end_inset

 is geometric variation
\end_layout

\begin_layout Standard
Lagrange Polynomial
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
L=J+\int\int\hat{U}\cdot Rd\Omega dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\hat{U}=(\hat{\rho,}\hat{v}_{i},\hat{e})$
\end_inset

 is the vector of adjoint variables
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\delta J^{(t)}=\delta L^{(t)}= & \int_{0}^{T}\int\hat{U}\cdot Rd(\delta\Omega)dt\nonumber \\
 & +\int_{0}^{T}\int\delta\hat{U}^{(lc)}\cdot Rd\Omega dt\nonumber \\
 & +\int_{0}^{T}\int\hat{U}\cdot\delta R^{(lc)}d\Omega dt\nonumber \\
 & +\int_{0}^{T}\left[\int j_{\Omega}^{(lc)}d\Omega+\int_{\Gamma_{trg}}j_{\Gamma}d\Gamma\right]dt\nonumber \\
 & +\int_{0}^{T}\left[\int_{\Omega_{trg}}j_{\Omega}d(\delta\Omega)+\int_{\Gamma_{trg}}j_{\Gamma}d(\delta\Gamma)\right]dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\delta J^{(t)}= & \int_{0}^{T}\int\left[\frac{\partial\delta U^{(l)}}{\partial t}+\frac{\partial}{\partial x_{i}}\left(\delta U^{(l)}\cdot\frac{\partial F_{i}}{\partial U}\right)\right]\cdot\hat{U}d\Omega dt\nonumber \\
 & +\int_{0}^{T}\left[\int_{\Omega_{trg}}\delta U^{(lc)}\cdot\frac{\partial j_{\Omega}}{\partial U}d\Omega+\int_{\Gamma_{trg}}\delta U^{(lc)}\cdot\frac{\partial j_{\Gamma}}{\partial U}d\Gamma\right]dt\nonumber \\
 & +\int_{0}^{T}\left[\int_{\Omega_{trg}}j_{\Omega}d(\delta\Omega)+\int_{\Gamma_{trg}}j_{\Gamma}d(\delta\Gamma)\right]dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\delta J^{(t)}= & \int_{0}^{T}\left[\int\delta U^{(l)}\cdot\left(-\frac{\partial\hat{U}}{\partial t}-\frac{\partial F_{i}}{\partial U}\cdot\frac{\partial\hat{U}}{\partial x_{i}}\right)d\Omega+\int_{\Omega_{trg}}\delta U^{(lc)}\cdot\frac{\partial j_{\Omega}}{\partial U}d\Omega\right]dt\nonumber \\
 & +\int_{0}^{T}\left[\int\delta U^{(l)}\cdot\frac{\partial F_{i}}{\partial U}\cdot\hat{U}n_{i}d\Gamma+\int_{\Gamma_{trg}}\delta U^{(lc)}\cdot\frac{\partial j_{\Gamma}}{\partial U}d\Gamma\right]dt\nonumber \\
 & +\left[\int\delta U^{(l)}\cdot\hat{U}d\Omega\right]_{0}^{T}\nonumber \\
 & +\int_{0}^{T}\left[\int_{\Omega_{trg}}j_{\Omega}d(\delta\Omega)+\int_{\Gamma_{trg}}j_{\Gamma}d(\delta\Gamma)\right]dt
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $n_{i}$
\end_inset

 is a boundary unit vector
\begin_inset Formula 
\begin{align*}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
-\frac{\partial\hat{U}}{\partial t}-\frac{\partial F_{i}}{\partial U}\cdot\frac{\partial\hat{U}}{\partial x_{i}}=-\frac{\partial\hat{U}}{\partial t}-\underbar{\underline{A}}_{i}^{T}\cdot\frac{\partial\hat{U}}{\partial x_{i}} & =0\thinspace\thinspace\thinspace\textrm{in}\thinspace\thinspace\Omega/\Omega_{trg}\nonumber \\
-\frac{\partial\hat{U}}{\partial t}-\underbar{\underline{A}}_{i}^{T}\cdot\frac{\partial\hat{U}}{\partial x_{i}} & =-\frac{\partial j_{\Omega}}{\partial U}\thinspace\thinspace\text{in}\thinspace\thinspace\Omega_{trg}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\delta U^{(l)}\cdot\frac{\partial F_{n}}{\partial U}\cdot\hat{U} & =0\thickspace\text{on}\thickspace\Gamma/\Gamma_{trg}\nonumber \\
\delta U^{(l)}\cdot\left[\frac{\partial F_{n}}{\partial U}\cdot\hat{U}+\frac{\partial j_{\Gamma}}{\partial U}\right] & =0\thickspace\text{on}\thickspace\Gamma_{trg}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Adjoint initialization:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{U}(t=T)=0\thickspace\text{in}\thickspace\Omega
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Forward initialization:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\delta U^{(l)}(t=0)=0\thickspace\text{in}\thickspace\Omega
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\delta J^{(t)}=\int_{0}^{T}\int_{\Gamma_{dsg}}\delta U^{(l)}\cdot\frac{\partial F_{i}}{\partial U}\cdot\hat{U}n_{i}d\Gamma dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
0 & = & v_{n}^{old}\vert_{\underbar{x}_{old}}=v_{n}^{new}\vert_{\underbar{x}_{new}}\approx\left[v_{n}^{old}+\delta v_{n}^{(l)}+\delta v_{n}^{(c)}\right]_{\underbar{x}_{old}}\nonumber \\
 &  & \leadsto\delta v_{n}^{(l)}=-\delta n\frac{\partial v_{n}}{\partial n}\thickspace\text{on old }\Gamma_{dsg}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\delta n$
\end_inset

 is perturbations normal to the boundary of 
\begin_inset Formula $\Gamma_{dsg}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial J^{(t)}}{\partial n}=\int_{0}^{T}\int_{\Gamma_{dsg}}-\frac{\partial v_{n}}{\partial n}\left[\rho\hat{\rho}+\rho v_{i}\hat{v}_{i}+\left(\rho e+p\right)\hat{e}\right]d\Gamma dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
only working on design area:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\delta J^{(t)}}{\delta V}=\int_{0}^{T}-\frac{\partial v_{n}}{\partial n}\left[\rho\hat{\rho}+\rho v_{i}\hat{v}_{i}+\left(\rho e+p\right)\hat{e}\right]dt\thickspace\text{ on }\Gamma_{dsg}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{F}^{(ij)}=f^{(i)}+f^{(j)}
\]

\end_inset

 so an equal weighting of the endpoints of the edge.
 again this is used on the edge based solve, and I do not believe that is
 how we are solving the system.
 If it is used, it is unstable so must be changed as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{F}^{(ij)}=\hat{f}^{(i)}+\hat{f}^{(j)}-\left|\lambda^{(ij)}\right|\left[\hat{U}^{(i)}-\hat{U}^{(j)}+\frac{\beta}{2}\underline{l}^{(ji)}\cdot\left(\nabla\hat{U}^{(i)}+\nabla\hat{U}^{(j)}\right)\right]_{0<\beta<1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $l^{(ji)}=x^{(j)}-x^{(i)}$
\end_inset

 so it is the direction where 
\begin_inset Formula $x^{(i)},x^{(j)}$
\end_inset

 are the endpoints of the edge.
 This is an edge based flow solver, so probably not what we are using in
 the FCT environment.
\end_layout

\begin_layout Standard
\begin_inset Formula $\lambda=\left|\underbar{v}\right|+c$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $c=\sqrt{\frac{\gamma p}{\rho}}$
\end_inset


\end_layout

\begin_layout Standard
and
\end_layout

\begin_layout Standard

\series bold
\begin_inset Formula 
\begin{equation}
\beta=1-\frac{\left|p^{(i)}-p^{(j)}+0.5l^{(ji)}\cdot\left(\nabla p^{(i)}+\nabla p^{(j)}\right)\right|}{\left|p^{(i)}-p^{(j)}\right|+\left|0.5l^{(ji)}\cdot\left(\nabla p^{(i)}+\nabla p^{(j)}\right)\right|}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
which gives a second and fourth order dampening when 
\begin_inset Formula $\beta$
\end_inset

 is 0 and 1 respectively.
 This may or may not be used because we are not using the RK4 version of
 the adjoint solver that is used in the paper.
 We are going to use the same FCT solver for adjoint that was used for forward
 for backward, and that will mean tht the problem of not truly accheiving
 duality like the paper will not happen to us, since if you use the same
 method in both the duality should amost certainly be preserved.
\end_layout

\begin_layout Standard
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!
\end_layout

\begin_layout Subsubsection*
Finite Element Method
\end_layout

\begin_layout Standard
Finite element method description
\end_layout

\begin_layout Subsubsection*
Jet Engine Noise
\end_layout

\begin_layout Standard
Jet engine noise can be divided into two distinct sections.
 The first section is engine noise.
 This includes the actual whir of the turbines along with the intake noise
 and the explosion of the fuel to drive the engine.
 At low speed outputs this is the dominant noise.
 For military jets, as are currently under consideration, the dominating
 noise is the jet flow noise.
 The pressure waves created by the faster moving jet flow interacting with
 the slower moving ambient air propogate much further down stream and are
 thus a problem much farther away.
 Flow noise can propogate in both directions and can be highly dtetrimental
 to the hearing of workers on flight decks as well as buildings neighboring
 air fields.
 Quite regularly, supersonic aircraft blast windows out of homes near airfields
 as the cross the sonic threshold and create the sonic boom.
\end_layout

\begin_layout Subsection*
Adjoint Verification
\end_layout

\begin_layout Standard
There have been no standard validation cases for adjoint based optimization
 of unsteady flows.
 All of the work done so far has been done with a single application in
 mind.
 They have been done with specific cases in mind and set up for maximization
 or minimization for one case or another.
 Of the papers written on adjoint based optimization, when they show examples
 to prove that the adjoint is working, they simply show a before and after
 case using the adjoint optimization scheme.
 These show that for the specific case, it does actually give an improvement
 in the intended quantity.
 This is great, but it does not guarantee that the adjoint solver is actually
 running correctly and not just happening to get lucky and get the correct
 movement for this one case.
 
\end_layout

\begin_layout Standard
To remedy this, we aim to design analytical test cases such that an adjoint
 solver can be verified against mathematically sound results.
 Being test cases, these will be simple cases but will provide exact results
 against which to compare the solver.
\end_layout

\begin_layout Subsection*
Previous Work
\end_layout

\begin_layout Subsubsection*
Jet Engine Noise Reduction
\end_layout

\begin_layout Standard
There have been a multitude of papers on jet engine noise reduction.
 The main twork that will be focused on in this paper is based on the work
 by Kailasanath et al.
 This work is on the addition of flow disrupters on the end of the exhaust
 nozzle called chevrons.
 These chevrons allow for the sheer regions to be minimized by helping to
 add some vorticity in the streamwise direction of the flow and thus increasing
 the mixing layer.
 The major benefit of this is a small reduction in noise in the aft direction,
 but a large reduction in the forward direction.
 Namely, the chevron addition helps to reduce and eliminate the screech
 from supersonic jets.
 Screech is the forward propogation of the shock wave from the supersonic
 gasses escaping the nozzle in the subsonic ambient air.
 The research also implies that the main noise-generating region of the
 noise that propogates to the far field is the shear layer noise and in
 order to reduce overall far field noise the goal should be to increase
 the mixing layer and thus decrease the shear layer.
 The pressure waves from the mixing layer tend to disipate in the wake of
 the flow in much less time than that of the shear noise.
 Arguably, this would be because the shear noise is escaping without being
 subjected to the vorticity of the mixing layer.
 
\end_layout

\begin_layout Standard
There have also been a number of suggestions for flow interrupters inserted
 into the nozzle of the jet exhaust.
 These are shown to reduce the noise level of the jets, but the need of
 military style jets to utilize every bit of thrust available tends to make
 these solutions a bit too expensive in the thrust cost to be deployable.
 For that reason, the research will be looking into ways of decreasing jet
 engine noise with a minimal and ideally negligible cost to thrust.
 
\end_layout

\begin_layout Standard
One possible solution which could provide both a reduction in noise and
 minimal cost to possibly even marginal gain in thrust is fluidic injection
 at the nozzle mouth.
 Fluidic injection could introduce streamwise vorticity while adding a bit
 of material flowing in the direction of the jet exhaust.
\end_layout

\begin_layout Standard
The code that has been most influential to this research in prior work is
 FeFlo.
 FeFlo is a finite element code capable of doing fully three dimensional
 Large Eddy Simulations for jet engine noise as well as working for a range
 of other applications.
 It was developed by Dr.
 Lohner who is currently at George Mason University.
 FeFlo has been used for adjoint based optimization as well.
 The main drawback for adjoint based optimization as has been used with
 FeFlo is the memory and communication costs as well as the thrashing of
 the hard drives by the repeated overwriting in the calculation.
\end_layout

\begin_layout Standard
Adjoint based optimization has been proposed as a very useful method of
 optimizing systems with large numbers of variables.
 This is because adjoint based optimization makes light work of these variables
 by using onyl one forward solver every iteration as opposed to a minimum
 of n iterations for a control space with n variables.
 Considering some real world control spaces have thousands to millions of
 control points, the finite difference form of optimization becomes intractable
 fairly quickly.
 Adjoint based optimization does have a drawback to it however.
 For an adjoint run to be possible, the adjoint solver needs to have access
 to all of the forward data in reverse order.
 The main problem from this is that in order to have access to the forward
 data in reverse order, one must either store all of the field data at every
 time step and then access it in reverse order or store it in a carefully
 planned way so that it can all be gotten to in one form or another.
 Some people have gotten around this cost by only storing some of the checkpoint
s and simply interpolating between them.
 This does cut some of the cost, but it also introduces more unneccesary
 error into the simulation.
 Others have used Monte Carlo Methods to emulate adjoint based optimization,
 but that requires the running of thousands of forward simulations to get
 a reasonable level of confidence that almost negates the benefit of cutting
 out the need of running all of the simulations for each control point.
 One solution to the data crunch, at least in terms of storage, is to do
 checkpointing of the forward solutions.
 In this manner, one would store a strategic set of forward states and then
 recalculate the in between steps when neccesary.
 This allows for much longer runs and much larger simulations in the same
 storage space.
 The current research looks into the problem of communication costs in the
 adjoint based optimization realm.
\end_layout

\begin_layout Subsubsection*
Adjoint Checkpointing 
\end_layout

\begin_layout Paragraph*
Reduced Memory
\end_layout

\begin_layout Standard
One method which has been mitigate the storage costs associated with an
 adjoint simulation has been to reduce the amount stored via data compression,
 downsampling, and interpolation.
 From the reduced data, intermediate points in space and time are interpolated
 and used for calculation of the adjoint~
\backslash
cite{Wei04, Kim11}.
 This allows for larger run sizes, but it also introduces additional error,
 the effect of which is difficult to quantify, which is unnecessary, in
 view of the availability of effective checkpointing methods.
\end_layout

\begin_layout Paragraph*
Monte Carlo Methods
\end_layout

\begin_layout Standard
Monte Carlo methods have been used by Wang et al~
\backslash
cite{Wan08_MC} to avoid running the adjoint solver in reverse, to circumvent
 the need to access the primal solution in reverse time order.
 However, this method also introduces additional error, as well as an uncertain
 cost associated with multiple forward runs as required by the Monte Carlo
 method.
 
\end_layout

\begin_layout Paragraph*
Equidistant Checkpointing
\end_layout

\begin_layout Standard
Equidistant checkpointing is the most obvious of checkpointing techniques.
 The user simply stores checkpoints every so many steps and then recalculates
 the rest of the points with another run in between.
 This method does not introduce any extra error into the solution, but it
 is not an optimal use of the space.
 The implementations of this method have been writing everything to disk
 as well which introduces a good deal of overhead in terms of storage costs
 and IO.
 This method is the easiest to implement with the concept of holding all
 intermediate values in memory, as the code would simply store a checkpoint
 every N steps if the memory could hold N steps at a time.
 The ease of programming this type of approach is offset by the fact that
 once the run sizes get to be top a reasonable level, the number of reads
 and writes to disk get to be very large.
 This again runs into the problem then of storage limits and IO overhead.
\end_layout

\begin_layout Paragraph*
Binomial Checkpointing
\end_layout

\begin_layout Standard
Binomial checkpointing schedules checkpoints so that the available storage
 is always kept as full as possible.
 As a result, it allows the adjoint solver to store more checkpoints than
 equidistant checkpointing while retaining the benefit of not introducing
 any additional error.
 For the given number of recalculations allowed, thus stipulating the allowed
 number of recursions, binomial checkpointing gives optimal use of storage
 space.
 
\end_layout

\begin_layout Standard
Revolve~
\backslash
cite{Gre00}, a well known binomial checkpointing algorithm, has been used
 with a large number of applications.
 This scheduling software minimizes the number of recalculations given the
 number of steps to take and the number of checkpoints available.
 This algorithm allows for the user's code to perform all calculation aside
 from the actual determination of checkpointing schedule.
 
\end_layout

\begin_layout Standard
For the current implementation, the control period is known, allowing for
 checkpointing schedules to be made a priori.
 For some applications, this is not possible and thus there is a need for
 dynamic checkpointing, where checkpointing cannot be scheduled a priori.
 Examples of dynamic checkpointing are A-Revolve~
\backslash
cite{Hin05}, online checkpointing~
\backslash
cite{Heu06, Stu08}, and minimal repetition dynamic checkpointing~
\backslash
cite{Wan09}.
 Dynamic checkpointing may be looked into for future applications if the
 control period becomes less predictable.
 
\end_layout

\begin_layout Standard
Context switching can be a bottleneck for some codes using binomial checkpointin
g.
 If the primal and adjoint solvers are not tightly coupled, e.g.
 using the same temporary arrays and grid structures, there may be a significant
 cost to switch between the two solvers.
 This cost becomes large, given the frequent switching that occurs with
 binomial checkpointing, in contrast to equidistant checkpointing, where
 switching is make less frequent.
 It is therefore crucial that an adjoint solver employing binomial checkpointing
, be able to switch between the primal and adjoints solver with zero overhead.
\end_layout

\begin_layout Standard
There have been quite a few attempts to make checkpointing of this type
 nicer in that it wold not have had to ever be run previously to figure
 out when to start and stop the adjoint solver.
 Until these works, the binomial checkpointing method relied on knowing
 how many total steps would be taken so that the method could store all
 of the data in the smallest size possible.
 This is A-Revolve and all of the things like it.
 With these codes, as the simulation runs, it continually updates what is
 stored to maximize storage ability as well as minimizing the recalculations.
 This is a great advancement for a good number of applications, but it is
 not really necessary for the work being done on jet noise.
 To know the level of noise generated by the current set-up, the forward
 simulation needs to be run anyway.
 With this in mind, it is simple enough to simply designate from the forward
 run data the adjoint begin and end points.
 If the start and end points are set ahead of time, the on-line checkpointing
 methods are not beneficial.
 
\end_layout

\begin_layout Standard
Even with the binomial checkpointing schemes implemented by the others,
 the concept of running full 3D LES runs had been out of reach due to the
 intense strain of storage on space and time.
 The life of the hard drives used for the simulations using binomial checkpointi
ng and very large numbers of time steps would also be greatly reduced if
 the drives used were traditional hard drives.
 One approach used to cut these problems down a bit was to move from standard
 hard disk storage to solid state drives.
 This fixes some of the overhead cost as the cost of reading and writing
 data to and from solid state drives is less than that of traditional hard
 drives.
 It however brings with it problems of limited numbers of available writes
 for solid state drives.
 Disk based binomial methods require rewriting in the same place on the
 disk very large numbers of times each time a run takes place.
 The benefit though is still not as good as going away from being dependent
 on writing to disk as the main way of progressing.
 Even with solid state drives, the cost of running the adjoint with these
 approaches was highly dependent on IO speed.
 This is a major problem as IO speed is typically out of the user's control
 and varies widely on different systems.
\end_layout

\begin_layout Standard
With the binomial implementation in 
\backslash
cite{Tor12} and many like it, the benefit of the method is only in the added
 storage capacity.
 The problem is that the same amount of data is still written to hard disk.
 The storage method on the disk does allow for much more to be stored, but
 the time it takes to store the information is still the same.
 This means that even though the binomial implementation makes available
 a much larger amount of simulation, the overwhelming cost of writing to
 the disk still keeps the larger of the simulation out of reach.
 In addition, writing the information to the same place on the hard drive
 repeatedly shortens the lives of the hard drives in every system on which
 the code is run.
\end_layout

\begin_layout Subsection*
Current Research
\end_layout

\begin_layout Subsubsection*
Checkpointing
\end_layout

\begin_layout Standard
The checkpointing methods used previously for static checkpointing for adjoint
 based optimization were all designed for solving what was seen as the most
 important issue at the time.
 This issue was storage.
 With the original methods, the cases were extremely small as was the storage
 potential of the computers.
 As the size of hard disks got larger, the size of porblems could also get
 larger and people started seeing that they would need special methods to
 get a full meaningful run done on any machine.
 The original idea in adjoint based optimizatiion was to write out every
 step to disk and then simply read them back in in reverse order to use
 them for the reverse solver.
 This was extremely prohibitive if the size of the problem was anything
 more tan trivial.
 For that reason, (person credited with this) developed the equidistant
 checkpointing method.
 The storage capacity of the equidistant checkpointing method is as follows
 
\begin_inset Formula 
\begin{eqnarray*}
n & = & \left\lfloor \frac{size_{dump}}{size_{disk}}\right\rfloor \\
s & = & k*(n-k)\\
k & < & n\\
optimal\thinspace k & = & \frac{n}{2}\\
s & = & \frac{n^{2}}{4}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $n,$
\end_inset

 
\begin_inset Formula $k,$
\end_inset

 and 
\begin_inset Formula $s$
\end_inset

 are the original storage capacity of the disk, number of steps between
 checkpoints, and new storage capacity of the disk, respectively.
 With the right choice of 
\begin_inset Formula $k=\frac{n}{2}$
\end_inset

, this method was able to extend the size of runs available by a good bit.
 
\end_layout

\begin_layout Standard
As computers continued to get faster, and larger problems were considered,
 even the storage space created by the equidistant checkpointing method
 proved to be inadequate.
 This called for a new method that could allow for even further increase
 of the storage capabilities.
 The answer for this came in the form of Revolve, a program designed to
 maximize the amount of steps able to fit into the disk of any machine.
 This method has become the favored method in the field, with different
 versions being made to take care of multiple different cases, including
 A-Revolve, the program designed to do checkpointing on the fly without
 prior knowledge of the size of the problem.
 However, for the LES problems being considered here, the size of the problem
 is well known before hand and thus A-Revolve is of no benefit over Revolve.
 
\end_layout

\begin_layout Standard
From Revolve came a binomial checkpointing algorithm that is very useful.
 This algorithm has been used in multiple other places and can have a great
 affect on the storage capacity of a disk as shown below.
 
\begin_inset Formula 
\begin{eqnarray*}
n & = & \left\lfloor \frac{size_{dump}}{size_{disk}}\right\rfloor \\
s & = & \sum_{i=1}^{n}i\\
 & = & \frac{n*(n+1)}{2}\\
 & = & \frac{n^{2}+n}{2}
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $s$
\end_inset

 are again original storage capacity of disk and new storage capacity of
 disk, respectively.
 This is a huge gain in possible problem size, but still was not enough
 to allow for some of the real world simulations needed.
 
\end_layout

\begin_layout Standard
The beauty of the binomial method is that it could be nested inside of itself
 to create that much more room in the disk.
 Each new nesting of the algorithm costs roughly the same as a forward run
 from recomputation of the intermediate steps, but it does allow for increases
 in storage potential to extremely large sizes.
 
\end_layout

\begin_layout Standard
All of these methods focused mainly on the increased storage time, although
 Revolve does take into account the number of recalculations and is able
 to minimize these recalcuations for a given set of data.
 One of the things that is left out of the previoius methods is consideration
 of using memory instead of disk for storage.
 Writing to and reading from hard disk is a very expensive task and can
 quickly become the most expensive part of and adjoint run using the previous
 methods.
 Our goal was to alleviate as much of the pain of writing to and reading
 from disk as possible by creating a routine that foused mainly on the memory,
 but used the disk in the case that memory was insufficient.
 With that in mind, we developed a checkpointing method that employs the
 binomial checkpointing method in the memory along with a version of the
 equidistant checkpointing method on the hard disk.
 First the memory based checkpointing.
 As with the original we have the storage capacity of the memory to be
\begin_inset Formula 
\begin{eqnarray*}
n_{memory} & = & \left\lfloor \frac{size_{dump}}{size_{memory}}\right\rfloor \\
s_{memory} & = & \frac{n_{memory}^{2}+n_{memory}}{2}
\end{eqnarray*}

\end_inset

which allows for quite a few steps to be stored in the memory of the machine.
 In one run of a fully 3D simulations, the dump size was found to be 2.3GB.
 The problem was broken up over 1024 cores, thus the storage required per
 core was only 0.002246GB.
 The cores each had approximately 1.8125GB of memory each.
 
\begin_inset Formula 
\begin{eqnarray*}
n_{memory} & = & \frac{1.8125}{.002246}=806\thinspace steps\\
s_{memory} & = & \frac{806^{2}+806}{2}=325221\thinspace steps
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Thus our method was able to store 157080 steps without ever needing to write
 to hard disk.
 For the hard disk portion, the method writes to disk only if necessary,
 but will write to disk every 
\begin_inset Formula $s_{memory}$
\end_inset

 steps, thus creating an equidistant-type checkpointing method on the hard
 disk.
 Everything will be stored on memory for the intermediate recalcuations,
 thus only the checkpoints will be written to disk.
 The user quota on the machine for this test was 2TB, thus giving
\begin_inset Formula 
\begin{eqnarray*}
n_{disk} & = & \frac{2000}{2.3}=869\thinspace checkpoints\\
s_{total} & = & s_{memory}*n_{disk}=282617049\thinspace steps
\end{eqnarray*}

\end_inset

this means that the simulation could now run for more than 282 million time
 steps.
 This allows for great increases in the size of problem run.
 
\end_layout

\begin_layout Standard
For the same size run, say 1 million time steps, we compare the usage of
 the two reasonable approaches.
 For the case of binaomial checkpointing using the disk as the primary storage
 place, the minimal storage for only recalculting steps 1 time would be
\begin_inset Formula 
\begin{eqnarray*}
1000000 & = & \frac{n^{2}+n}{2}\\
2000000 & = & n^{2}+n\\
n & = & \frac{-1\pm\sqrt{1+8000000}}{2}\\
n & = & 1414\thinspace steps
\end{eqnarray*}

\end_inset

at 2.3 GB per step, this comes to a total of roughly 3.252 TB of data stored
 at any one time.
 More over, every step would at one point be written to the hard disk, so
 in terms of writes and reads the communication would be 2.3 million GB or
 about 2.3 PB of data each way.
 The storage requirements would put this out of the range of our alloted
 space for the computer and would be prohibitively time consuming with the
 transfer of so much data back and forth.
 With our method, the memory would be used first, and the hard disk only
 written to every 325221 steps, thus requiring 3 hard checkpoints.
 This means that our method would require 6.9 GB of storage on the hard drive
 and would communicate 6.9 GB in terms of reads and writes each way.
 This means the binomial method costs 471 times and 333333 times as much
 as our method for the storage and communication costs respectively.
 Unlike the other methods, our method can also be expanded to more cores,
 thus increasing the number of steps that can be stored in memory.
 We can increase to 1797 cores and eliminate the need for writing to the
 hard drive at all.
 With the other methods, no matter how many cores were used for the calculations
, the storage and communication cost would be the same in terms of step
 storage.
 The storage costs of the binomial method could be cut down by allowing
 more and more repeats of calculations, but this would still not change
 the fact that every step would eventually be written to the hard drive,
 thus keeping the extremely high communication cost.
 
\end_layout

\begin_layout Standard
Allowing for 2 recalculations of the intermediate steps would cut the cost
 down to 181 steps stored on disk.
 This is a significant reduction from 1414 but has the added cost of another
 forward run.
 The problem that still plagues this method is that the munt of data written
 and read stays the same as the method is still storing everything in the
 hard drive and thus must go back to it for anything it needs.
\end_layout

\begin_layout Standard
Another concern of the problem is that these extremely large problems lend
 themselves well to running on GPU systems.
 GPUs are extremely fast, but have rather low storage capacity.
 The fast nature of the GPUs puts even more relative cost on having to write
 out to disk, as even more steps can be calculated in the same amount of
 time it might take to write out a single step.
 With some of the previous methods, the concept of using a GPU system is
 not completely thrown out, but the cost of I/O using the previous methods
 would so far outweigh the cost of the actual runs hat it would be almost
 pointless to use them.
 With the new method, the number of reads and writes is minimal, and thus
 the cost of the run is based on the cost of the calculation, instead of
 the cost of I/O.
 This is very important because this allows for considerable speedup of
 the code as chips continue to get faster and the code becomes even more
 optimized.
 With the cost of I/O domination the cost of the run, the only way to get
 considerable speed-up is to sit around waiting on a new storage system
 that gets very much faster.
 
\end_layout

\begin_layout Standard
The code is written to be optimal running on whichever platform it is run.
 The GPU implementation allows for very fast processing of the data with
 the drawback of having very little storage capability in the attached memory.
 For this type of application, we are considering including the second level
 of recursion in the checkpointing scheme in memory.
 This would allow many more steps to be taken without the need for writing
 to disk.
 The steps available with the second level of checkpointing are as follows
\begin_inset Formula 
\begin{eqnarray*}
n & = & \left\lfloor \frac{size_{dump}}{size_{memory}}\right\rfloor \\
s_{memory_{1}} & = & \sum_{i=1}^{n}i\\
 & = & \frac{n*(n+1)}{2}\\
s_{memory_{2}} & = & \sum_{i=1}^{n}\sum_{j=1}^{i}j\\
 & = & \sum_{i=1}^{n}\frac{i*(i+1)}{2}\\
 & = & \sum_{i=1}^{n}\frac{i^{2}}{2}+\sum_{i=1}^{n}\frac{i}{2}\\
 & = & \frac{n*(n+1)*(2n+1)}{12}+\frac{n*(n+1)}{4}\\
 & = & \frac{(n*(n+1)*(2n+1))+(3n*(n+1))}{12}\\
 & = & \frac{n*(n+1)*(n+2)}{6}\\
\frac{s_{memory_{2}}}{s_{memory_{1}}} & = & \frac{n+2}{3}
\end{eqnarray*}

\end_inset

the benefit is easy to see from the above equations.
 For further example consider a GPU system which has memory for each GPU
 in the amount of 6GB.
 Again having a dump size of 2.3 GB and running on 64 GPUs, we have a per
 GPU dump size of 0.0359375 GB.
 
\begin_inset Formula 
\begin{eqnarray*}
n_{memory} & = & \frac{6}{0.0359375}=166\thinspace steps\\
s_{memory_{1}} & = & \frac{166*167}{2}=13861\thinspace steps\\
s_{memory_{2}} & = & \frac{166*167*168}{6}=776216\thinspace steps
\end{eqnarray*}

\end_inset

for a run of reasonable length, this is the difference between writing to
 hard drive on the order of 50 times and writing to the hard drive exactly
 0 times for the same number of recalculations.
 This method is extremely useful for the cases of very fast computation
 and very expensive communication where on a GPU the cost of a single write
 to disk can be the equivalent of calculting 1000's of steps.
 Since there is no extra work being done in the double nesting over the
 hard checkpointing, this method only makes sense as the option for GPU
 systems, while the relatively large memory size of CPU systems make the
 second checkpointing unneccesary.
 For this reason, the checkpointing method will be able to be determined
 by the user on compile time.
 Single checkpointing will always be active, but there will be an option
 for the user to turn on the double checkpointing if they feel they want
 it.
 
\end_layout

\begin_layout Standard
One of the other ways that people have looked into making adjoint based
 optimization is to use monte carlo methods to predict the motion.
 These methods allow for a solution to be calculated without running the
 simulation backward at all.
 The cost savings for this type of method are that the total costs goes
 from 
\begin_inset Formula $\log n$
\end_inset

 times the original where 
\begin_inset Formula $n$
\end_inset

 is the number of time steps in the old methods, to a constant multiple
 of the originl cost.
 This is traded off for the fact tht the solution is not exact.
 Our method now costs also a constant multiple of the original forward simulatio
n and gives an exact answer.
 Our method costs at most three times the time of the forward run.
 People have also used memory reduction methods to deal with the problem
 of lack of space for adjoint calculations, again with the tradeoff of not
 getting exact solutions and adding in a level of uncertainty that cannot
 really be known considering the level of knowledge about the adjoint solution
 in general.
 These methods are similar to running a much coarser grid and using the
 results of the coarser grid to map directly to the results from the fine
 grid.
 They are inexact, and typically just unusable for real applications.
\end_layout

\begin_layout Standard
One of the main advances that makes this method work so well is the fact
 that the forward solver and reverse solver are completely coupled.
 The only difference in the code between running the forward and reverse
 solvers is the setting of a flag value.
 This eliminates the cost of context switching which is a very high cost
 considering the number of times it must be done in the process of solving
 the adjoint problem.
 
\end_layout

\begin_layout Standard
On scalability of the algorithm, the benefit of checkpointing is only increased
 by every extra node it is connected to.
 More nodes mean less data per node and thus, less memory usage.
 This in turn allows for more steps to be stored in the memory and thus
 many more steps to be run without need for writing to the hard drive.
 
\end_layout

\begin_layout Subsubsection*
Adjoint Verification
\end_layout

\begin_layout Paragraph*
Entropy waves
\end_layout

\begin_layout Standard
the cost function for entropy waves is defined by 
\begin_inset Formula 
\[
\int_{\Omega_{t}}||\rho-\rho_{\infty}||_{2}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
substitution of the definition of density for Entropy wave case we get
\begin_inset Formula 
\[
\int_{\Omega_{t}}\left|\rho_{\infty}+A\thinspace sin\left[\pi\left(x-U_{\infty}t\right)\right]-\rho_{\infty}\right|^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Where A is the amplitude of the entropy wave.
 
\end_layout

\begin_layout Standard
for a measurement region from 
\begin_inset Formula $x_{0}$
\end_inset

 to 
\begin_inset Formula $x_{1}$
\end_inset

 and a simulation time from 
\begin_inset Formula $t_{0}$
\end_inset

 to 
\begin_inset Formula $t_{1}$
\end_inset

we get
\begin_inset Formula 
\[
\int_{t_{0}}^{t_{1}}\int_{x_{0}}^{x_{1}}\left(\rho_{\infty}+A\thinspace sin\left[\pi\left(x-U_{\infty}t\right)\right]-\rho_{\infty}\right)dx\thinspace dt
\]

\end_inset


\end_layout

\begin_layout Standard
upon integration by x, we get
\begin_inset Formula 
\[
\int_{t_{0}}^{t_{1}}\left(\rho_{\infty}x-\frac{A\thinspace cos\left[\pi\left(x-U_{\infty}t\right)\right]}{\pi}-\rho_{\infty}x\right)|_{x_{0}}^{x_{1}}dt
\]

\end_inset


\end_layout

\begin_layout Standard
evaluation gives
\begin_inset Formula 
\[
\int_{t_{0}}^{t_{1}}\left(\rho_{\infty}x_{1}-\frac{A\thinspace cos\left[\pi\left(x_{1}-U_{\infty}t\right)\right]}{\pi}-\rho_{\infty}x_{1}-\rho_{\infty}x_{0}+\frac{A\thinspace cos\left[\pi\left(x_{0}-U_{\infty}t\right)\right]}{\pi}+\rho_{\infty}x_{0}\right)dt
\]

\end_inset


\end_layout

\begin_layout Standard
simplification then yields
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{A}{\pi}\int_{t_{0}}^{t_{1}}\left(cos\left[\pi\left(x_{0}-U_{\infty}t\right)\right]-cos\left[\pi\left(x_{1}-U_{\infty}t\right)\right]\right)dt
\]

\end_inset


\end_layout

\begin_layout Standard
integrating over time
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{A}{\pi^{2}U_{\infty}}\left(sin\left[\pi\left(x_{1}-U_{\infty}t\right)\right]-sin\left[\pi\left(x_{0}-U_{\infty}t\right)\right]\right)|_{t_{0}}^{t_{1}}
\]

\end_inset


\end_layout

\begin_layout Standard
evaluating
\begin_inset Formula 
\[
\frac{A}{\pi^{2}U_{\infty}}\left(sin\left[\pi\left(x_{1}-U_{\infty}t_{1}\right)\right]-sin\left[\pi\left(x_{0}-U_{\infty}t_{1}\right)\right]-sin\left[\pi\left(x_{1}-U_{\infty}t_{0}\right)\right]+sin\left[\pi\left(x_{0}-U_{\infty}t_{0}\right)\right]\right)
\]

\end_inset


\end_layout

\begin_layout Standard
This is the cost function for the entropy wave.
 The derivative of the cost function with respect to amplitude of the entropy
 wave is
\begin_inset Formula 
\[
\frac{dCost}{dA}=\frac{1}{\pi^{2}U_{\infty}}\left(sin\left[\pi\left(x_{1}-U_{\infty}t_{1}\right)\right]-sin\left[\pi\left(x_{0}-U_{\infty}t_{1}\right)\right]-sin\left[\pi\left(x_{1}-U_{\infty}t_{0}\right)\right]+sin\left[\pi\left(x_{0}-U_{\infty}t_{0}\right)\right]\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*
Acoustic Waves
\end_layout

\begin_layout Standard
the cost function for acoustic wave is defined by 
\begin_inset Formula 
\[
\int_{\Omega_{t}}||p-p_{\infty}||_{2}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
substitution of the definition of pressure for acoustic wave case we get
\begin_inset Formula 
\[
\int_{\Omega_{t}}\left|p_{\infty}\left(1+\frac{\gamma-1}{2}\left(\frac{a_{\infty}m_{\infty}+\frac{2csin(kx)}{(\gamma+1)kt_{s}}}{a_{\infty}}-m_{\infty}\right)\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}-p_{\infty}\right|^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
for a measurement region from 
\begin_inset Formula $x_{0}$
\end_inset

 to 
\begin_inset Formula $x_{1}$
\end_inset

 and a simulation time from 
\begin_inset Formula $t_{0}$
\end_inset

 to 
\begin_inset Formula $t_{1}$
\end_inset

we get
\begin_inset Formula 
\[
\int_{t_{0}}^{t_{1}}\int_{x_{0}}^{x_{1}}\left(p_{\infty}\left(1+\frac{\gamma-1}{2}\left(\frac{a_{\infty}m_{\infty}+\frac{2csin(kx)}{(\gamma+1)kt_{s}}}{a_{\infty}}-m_{\infty}\right)\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}-p_{\infty}\right)dx\thinspace dt
\]

\end_inset


\end_layout

\begin_layout Standard
upon integration by x, we get
\begin_inset Formula 
\begin{eqnarray*}
\int_{t_{0}}^{t_{1}} & p_{\infty}^{2}[\frac{sec(kx_{1})}{ck(3\gamma-1)}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\frac{\left(\frac{3\gamma-1}{\gamma-1}\right)\frac{1}{4}}{m!n!\left(\frac{4\gamma-2}{\gamma-1}\right)}\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)^{m}\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)^{n}\\
 & -x_{1}-\frac{sec(kx_{0})}{ck(3\gamma-1)}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\frac{\left(\frac{3\gamma-1}{\gamma-1}\right)\frac{1}{4}}{m!n!\left(\frac{4\gamma-2}{\gamma-1}\right)}\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)^{m}\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)^{n}\\
 & +x_{0}]dt
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
simplification and sum evaluation gives
\begin_inset Formula 
\begin{eqnarray*}
\int_{t_{0}}^{t_{1}} & p_{\infty}^{2}[\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}\right)\\
 & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{01})-1)}{a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 & +x_{0}-x_{1}]dt
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
After integration by t we get
\begin_inset Formula 
\begin{eqnarray*}
 & p_{\infty}^{2}(t_{1}-t_{0})[\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}\right)\\
 & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{01})-1)}{a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 & +x_{0}-x_{1}]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
This is the cost function for the acoustic wave.
 The derivative of the cost function with respect to amplitude of the pressure
 wave is 
\begin_inset Formula 
\begin{eqnarray*}
\frac{dCost}{dc} & = & p_{\infty}^{2}(t_{1}-t_{0})[-\frac{sec(kx_{1})}{c^{2}(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & +\frac{sec(kx_{1})}{2c(16\gamma-8)k}\left(-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}\right)^{\frac{-1}{2}}\\
 &  & \left(\frac{-(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1))(\gamma-1)(sin(kx_{1})-1)+c(\gamma-1)(sin(kx_{1})-1)(\gamma-1)}{(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1))^{2}}\right)\\
 &  & \sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & +\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\left(\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}\right)^{-\frac{1}{2}}\\
 &  & \left(\frac{(c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s})(\gamma-1)(sin(kx_{1})+1)-c(\gamma-1)(sin(kx_{1})+1)(\gamma-1)}{\left(c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}\right)^{2}}\right)\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & +\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & (\gamma-1)sin(kx_{1})\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & +\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{2\gamma}{\gamma-1}\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}-1\right)}\\
 &  & \left(\frac{(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}\right)\left(e^{\left(\frac{-a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & +\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & \left(-\frac{(c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s})(\gamma-1)sin(kx_{1})-(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1}))(\gamma-1)}{\left(c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}\right)^{2}}\right)\\
 &  & +\frac{sec(kx_{1})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{1})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{1})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)\left(\frac{c(\gamma-1)sin(kx_{1})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}\right)\\
 &  & \left(\frac{\left(c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}\right)(\gamma-1)sin(kx_{1})-\left(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{1})\right)(\gamma-1)}{\left(c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}\right)^{2}}\right)\\
 &  & +\frac{sec(kx_{0})}{c^{2}(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & -\frac{sec(kx_{0})}{2c(16\gamma-8)k}\left(-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)}\right)^{\frac{-1}{2}}\\
 &  & \left(\frac{-(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1))(\gamma-1)(sin(kx_{0})-1)+c(\gamma-1)(sin(kx_{0})-1)(\gamma-1)}{(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1))^{2}}\right)\\
 &  & \sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\left(\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}\right)^{-\frac{1}{2}}\\
 &  & \left(\frac{(c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s})(\gamma-1)(sin(kx_{0})+1)-c(\gamma-1)(sin(kx_{0})+1)(\gamma-1)}{\left(c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}\right)^{2}}\right)\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & (\gamma-1)sin(kx_{0})\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{2\gamma}{\gamma-1}\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}-1\right)}\\
 &  & \left(\frac{(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}\right)\left(e^{\left(\frac{-a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}-1\right)\\
 &  & \left(-\frac{(c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s})(\gamma-1)sin(kx_{0})-(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0}))(\gamma-1)}{\left(c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}\right)^{2}}\right)\\
 &  & -\frac{sec(kx_{0})}{c(16\gamma-8)k}\sqrt{-\frac{c(\gamma-1)(sin(kx_{0})-1)}{a_{\infty}(\gamma-+1)kt_{s}+c(\gamma-1)}}\sqrt{\frac{c(\gamma-1)(sin(kx_{0})+1)}{c(\gamma-1)-a_{\infty}(\gamma+1)kt_{s}}}\\
 &  & \left(a_{\infty}(\gamma-1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)\left(\frac{c(\gamma-1)sin(kx_{0})}{a_{\infty}(\gamma+1)kt_{s}}+1\right)^{\left(\frac{2\gamma}{\gamma-1}\right)}\\
 &  & \left(e^{\left(-\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)-(\gamma+1)a_{\infty}kt_{s}}\right)}-1\right)\left(e^{\left(\frac{a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})}{c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}}\right)}\right)\\
 &  & \left(\frac{\left(c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}\right)(\gamma-1)sin(kx_{0})-\left(a_{\infty}(\gamma+1)kt_{s}+c(\gamma-1)sin(kx_{0})\right)(\gamma-1)}{\left(c(\gamma-1)+a_{\infty}(\gamma+1)kt_{s}\right)^{2}}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection*

\end_layout

\end_body
\end_document
